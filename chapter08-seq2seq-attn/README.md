Source code for chapter _Sequence-to-Sequence Models and Attention_. The examples include neural machine translation with RNN attention model, PyTorch transformer implemented from scratch, and text generation using the HuggingFace transformers library. 